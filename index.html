<!DOCTYPE html>
<html>

  <head>
    
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Waleed  Reda


</title>
<meta name="description" content="Personal webpage">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<!-- Uncommented -->
<!--  -->
<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>"> -->
<!--   -->

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-dark navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/teaching/">
                Teaching
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/docs/cv.pdf">
                CV
                
              </a>
          </li>
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Waleed</span>  Reda
    </h1>
     <p class="desc"></p>
  </header>

  <article>
    
    <div class="profile float-left">
      
        <img class="img-fluid rounded" src="/assets/img/prof_pic2.png">
      
      
        <div class="mail">
         <a href="mailto:%77%66%68%73%72@%6B%74%68.%73%65"><i class="fas fa-envelope"></i></a> wfhsr (at) kth.se
        </div>
      
      
        <div class="address">
          Isafjordsgatan 26, 16440 Kista Stockholm, Sweden

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>I received my PhD in 2022 from KTH Royal Institute of Technology and UCLouvain. On a high-level, my interests are mainly in distributed systems and networks. My research has led to the development of ultra low-latency distributed filesystems that use state-of-the-art storage and networking hardware (<a href="/papers/assise-osdi20.pdf">Assise</a>, <a href="/papers/linefs-sosp21.pdf">LineFS</a>). My <a href="/papers/redn-nsdi22.pdf">recent work</a> explores how to turn commodity NICs into general-purpose processors to exploit their computational power.</p>

<p>I was previously supported by the <a href="http://emjd-dc.eu/" target="_blank" rel="noopener noreferrer">EMJD-DC</a> fellowship.</p>

    </div>

    
      <div class="news">
  <h2>News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Feb 24, 2022</th>
          <td>
            
              <a href="http://sortbenchmark.org/RezSort2021.pdf" target="_blank" rel="noopener noreferrer">RezSort</a> breaks the JouleSort 2021 world record!


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Oct 26, 2021</th>
          <td>
            
              LineFS awarded <a href="https://sosp2021.mpi-sws.org/awards.html" target="_blank" rel="noopener noreferrer">best paper</a> at SOSP’21!


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jun 11, 2021</th>
          <td>
            
              Can RDMA support arbitrarily-complex offloads? The answer is yes! <a href="/papers/redn-nsdi22.pdf">RedN</a> accepted at NSDI’22.


            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Aug 4, 2020</th>
          <td>
            
              <a href="/papers/assise-osdi20.pdf">Assise</a> accepted at OSDI’20.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>Select publications</h2>
  <ol class="bibliography">
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">NSDI</abbr>
    
  
  </div>

  <div id="redan" class="col-sm-8">
    
      <div class="title">RDMA is Turing complete, we just did not know it yet!</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Reda, Waleed</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Canini, Marco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kostić, Dejan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Peter, Simon
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 19th USENIX Symposium on Networked Systems Design and Implementation (NSDI)</em>
      
      
      
        2022
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/papers/redn-nsdi22.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
      <a href="https://redn.io" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>It is becoming increasingly popular for distributed systems to exploit offload to reduce load on the CPU. Remote Direct Memory Access (RDMA) offload, in particular, has become popular. However, RDMA still requires CPU intervention for complex offloads that go beyond simple remote memory access. As such, the offload potential is limited and RDMA-based systems usually have to work around such limitations. We present RedN, a principled, practical approach to implementing complex RDMA offloads, without requiring any hardware modifications. Using self-modifying RDMA chains, we lift the existing RDMA verbs interface to a Turing complete set of programming abstractions. We explore what is possible in terms of offload complexity and performance with a commodity RDMA NIC. We show how to integrate these RDMA chains into applications, such as the Memcached key-value store, allowing us to offload complex tasks such as key lookups. RedN can reduce the latency of key-value get operations by up to 2.6× compared to state-of-the-art KV designs that use one-sided RDMA primitives (e.g., FaRM-KV), as well as traditional RPC-over-RDMA approaches. Moreover, compared to these baselines, RedN provides performance isolation and, in the presence of contention, can reduce latency by up to 35× while providing applications with failure resiliency to OS and process crashes.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SOSP</abbr>
    
  
  </div>

  <div id="kim2021linefs" class="col-sm-8">
    
      <div class="title">LineFS: Efficient SmartNIC Offload of a Distributed File System with Pipeline Parallelism</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Kim, Jongyul,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Jang, Insu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Reda, Waleed</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Im, Jaeseong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Canini, Marco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kostić, Dejan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kwon, Youngjin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Peter, Simon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Witchel, Emmett
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles (SOSP)</em>
      
      
      
        2021
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/papers/linefs-sosp21.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
      <a href="https://github.com/casys-kaist/LineFS" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    
      <a class="btn btn-sm z-depth-0" role="button"><img src="/assets/img/trophy.png" border="0" align="abscenter" height="15">  Best Paper</a>
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>In multi-tenant systems, the CPU overhead of distributed file systems (DFSes) is increasingly a burden to application performance. CPU and memory interference cause degraded and unstable application and storage performance, in particular for operation latency. Recent client-local DFSes for persistent memory (PM) accelerate this trend. DFS offload to SmartNICs is a promising solution to these problems, but it is challenging to fit the complex demands of a DFS onto simple SmartNIC processors located across PCIe. We present LineFS, a SmartNIC-offloaded, high-performance DFS with support for client-local PM. To fully leverage the SmartNIC architecture, we decompose DFS operations into execution stages that can be offloaded to a parallel datapath execution pipeline on the SmartNIC. LineFS offloads CPU-intensive DFS tasks, like replication, compression, data publication, index and consistency management to a Smart-NIC. We implement LineFS on the Mellanox BlueField Smart-NIC and compare it to Assise, a state-of-the-art PM DFS. LineFS improves latency in LevelDB up to 80% and throughput in Filebench up to 79%, while providing extended DFS availability during host system failures.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">OSDI</abbr>
    
  
  </div>

  <div id="assise" class="col-sm-8">
    
      <div class="title">Assise: Performance and Availability via Client-local NVM in a Distributed File System</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Anderson, Thomas E,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Canini, Marco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kim, Jongyul,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kostić, Dejan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kwon, Youngjin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Peter, Simon,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Reda, Waleed*</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Schuh, Henry N,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Witchel, Emmett
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 14th USENIX Symposium on Operating Systems Design and Implementation (OSDI)</em>
      
      
      
        2020
      
      
      </div>
      <div class="periodical">
        <b>* Lead student author</b>
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/papers/assise-osdi20.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
      <a href="https://github.com/ut-osa/assise" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">Code</a>
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The adoption of low latency persistent memory modules (PMMs) upends the long-established model of remote storage for distributed file systems. Instead, by colocating computation with PMM storage, we can provide applications with much higher IO performance, sub-second application failover, and strong consistency. To demonstrate this, we built the Assise distributed file system, based on a persistent, replicated coherence protocol that manages client-local PMM as a linearizable and crash-recoverable cache between applications and slower (and possibly remote) storage. Assise maximizes locality for all file IO by carrying out IO on process-local, socket-local, and client-local PMM whenever possible. Assise minimizes coherence overhead by maintaining consistency at IO operation granularity, rather than at fixed block sizes.
We compare Assise to Ceph/BlueStore, NFS, and Octopus on a cluster with Intel Optane DC PMMs and SSDs for common cloud applications and benchmarks, such as LevelDB, Postfix, and FileBench. We find that Assise improves write latency up to 22x, throughput up to 56x, fail-over time up to 103x, and scales up to 6x better than its counterparts, while providing stronger consistency semantics.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li>
<div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">SIGCOMM</abbr>
    
  
  </div>

  <div id="rambler" class="col-sm-8">
    
      <div class="title">Path Persistence in the Cloud: A Study of the Effects of Inter-Region Traffic Engineering in a Large Cloud Provider’s Network</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Reda, Waleed</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Bogdanov, Kirill,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Milolidakis, Alexandros,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ghasemirahni, Hamid,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chiesa, Marco,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Maguire Jr, Gerald Q,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kostić, Dejan
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>ACM SIGCOMM Computer Communication Review</em>
      
      
      
        2020
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/papers/rambler-ccr20.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
      
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>A commonly held belief is that traffic engineering and routing changes are infrequent. However, based on our measurements over a number of years of traffic between data centers in one of the largest cloud provider’s networks, we found that it is common for flows to change paths at ten-second intervals or even faster. These frequent path and, consequently, latency variations can negatively impact the performance of cloud applications, specifically, latency-sensitive and geo-distributed applications. Our recent measurements and analysis focused on observing path changes and latency variations between different Amazon aws regions. To this end, we devised a path change detector that we validated using both ad hoc experiments and feedback from cloud networking experts. The results provide three main insights: (1) Traffic Engineering (TE) frequently moves (TCP and UDP) flows among network paths of different latency, (2) Flows experience unfair performance, where a subset of flows between two machines can suffer large latency penalties (up to 32% at the 95th percentile) or excessive number of latency changes, and (3) Tenants may have incentives to selfishly move traffic to low latency classes (to boost the performance of their applications). We showcase this third insight with an example using rsync synchronization. To the best of our knowledge, this is the first paper to reveal the high frequency of TE activity within a large cloud provider’s network. Based on these observations, we expect our paper to spur discussions and future research on how cloud providers and their tenants can ultimately reconcile their independent and possibly conflicting objectives. Our data is publicly available for reproducibility and further analysis at http://goo.gl/25BKte.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
</ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%77%66%68%73%72@%6B%74%68.%73%65"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=HfibOt0AAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/wreda" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/waleed-reda" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a>












<a href="https://wreda.github.io/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a>

      </div>
      <div class="contact-note"></div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    © Copyright 2022 Waleed  Reda.
    
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
